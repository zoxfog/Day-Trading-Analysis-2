{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Data Extraction\n",
    "\n",
    "In this section we manualy insert the the key core data which consist of symbol, entry/exit time and date, entry price, exit price, and some additional tags. Based on the symbol, date and time keys we download additional 1 minute,1 hour and 1 day bar data and fundamental data for each symbol and date inserted.\n",
    "\n",
    "Sources:\n",
    "\n",
    "* 1 minute bar data: Interactive Brokers intraday data and Yahoo Finance.\n",
    "* 1 hour bar data: Yahoo Finance.\n",
    "* 1 day bar data: Yahoo Finance.\n",
    "* Fundamentals data: Yahoo Finace.\n",
    "\n",
    "The data from Yahoo Finance will be downloaded using the yfinance library and the data from Interactive Brokers will be downloaded using the Interactive Brokers API (only possible with a valid IB account and a monthly data subscrition).\n",
    "\n",
    "The trade picking process is carried out in a discretionary manner (manualy) using the TWS Interactive Brokers trading platform, which brings us to reason why the 1 minute data is downloaded from Interactive Brokers. Yahoo Finance 1 minute data will be used only if necessary depending on the accuracy and availability of the Interactive Brokers data, in other words 1 minutes Yahoo Finance data is used for backup.\n",
    "\n",
    "Since data from Yahoo Finance is relatively accurate, reliable and easily downloaded it is sufficent for the 1 hour and 1 day bar data which is why data of these time periods from Interactive Brokers is unnecessary. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from ibapi.client import EClient\n",
    "from ibapi.wrapper import EWrapper\n",
    "from ibapi.contract import Contract\n",
    "import pandas as pd\n",
    "import threading\n",
    "import datetime\n",
    "import time\n",
    "import os #kill the kernel\n",
    "import sys\n",
    "import yfinance as yf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trades Snap-Shot Entry (daily manual data entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##### symbol #####\n",
    "symbol = 'OCGN'\n",
    "\n",
    "##### intended entry #####\n",
    "intended_entry = 7.45\n",
    "\n",
    "##### SL #####\n",
    "SL = 7.23\n",
    "\n",
    "##### Generic Exit #####\n",
    "exit = 7.23\n",
    "\n",
    "##### Entry Time #####\n",
    "entry_time = datetime.datetime(2021,4,22,10,44)\n",
    "\n",
    "#### General Exit Time #####\n",
    "#NOTE: if exited not on SL then always write the following candle after the exit signal candle\n",
    "exit_time = datetime.datetime(2021,4,22,11,15)\n",
    "\n",
    "#### VWAP TAG ##### \n",
    "#  BO,  SUPPORT,  FALSE\n",
    "vwap_tag=\"SUPPORT\"\n",
    "\n",
    "#### Pattern #####\n",
    "# W- wedge, F - flag, AT -ascending triangle, DT - descending triangle, ST - symetrical triangle, R -  rectangle, P- penannt\n",
    "pattern ='ST'\n",
    "\n",
    "#### Catalyst #####\n",
    "# H  - hype, L - leading industry/sector, C - news catalyst\n",
    "catalyst = \"C\"\n",
    "\n",
    "\n",
    "#### Strategy ####\n",
    "strategy =\"BO\"\n",
    "\n",
    "#### Entry ####\n",
    "entry = intended_entry\n",
    "###############################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Errors\n",
    "\n",
    "This cell validates the manual data entrys to avoid errors and future cleaning.\n",
    "Makes sure dates, time and prices are aligned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# errors:\n",
    "if SL>=intended_entry:\n",
    "    print(\"******** ERROR: SL higher than entry ********\")\n",
    "    sys.exit()\n",
    "    \n",
    "\n",
    "if (entry_time>exit_time) or (entry_time.date()!=exit_time.date()):\n",
    "    print(\"******** ERROR: Incorrect entry time or exit time  ********\")\n",
    "    sys.exit()\n",
    "    \n",
    "day_start = datetime.datetime.combine(entry_time.date(),datetime.time(9,30))\n",
    "day_end = datetime.datetime.combine(entry_time.date(),datetime.time(16,0))\n",
    "    \n",
    "if (entry_time<day_start or entry_time>=day_end) or (exit_time<day_start or exit_time>=day_end):\n",
    "    print(\"******** ERROR: Invalid entry time or exit time, exceeds the trading hours range  ********\")\n",
    "    sys.exit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store The Core and Fundamentals Data\n",
    "\n",
    "Based on given symbol and date, download the fundamental data of that given symbol and date and store it in the Fundamentals dataset for future analysis and prediciton. Locally store the core data as insterted above and the freshly downloaded fundamental data alongside the data previously added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the new core data row and core keys.\n",
    "\n",
    "core_key = {\"Symbol\":symbol,\"Date\": entry_time.date()}\n",
    "core_dict = {\"Entry Time\": entry_time.time(),\"Exit Time\": exit_time.time(), \"Intended Entry\":intended_entry,\n",
    "\"Entry\": entry, \"SL\": SL,\"Exit\": exit,\"Pattern\": pattern,\"VWAP Tag\": vwap_tag,\"Strategy\":strategy,\"Catalyst\":catalyst,\"Download\":0}\n",
    "\n",
    "# import the datasets \n",
    "core_data =  pd.read_excel('Core Data.xlsx')  \n",
    "f_data =  pd.read_excel('Fundamentals.xlsx')\n",
    "\n",
    "# a function that merges to dictionaries\n",
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()   # start with x's keys and values\n",
    "    z.update(y)    # modifies z with y's keys and values & returns None\n",
    "    return z\n",
    "\n",
    "# timestamp - Datetime type changes\n",
    "timestamp_date = pd.Timestamp(entry_time.date())\n",
    "strftime_time = entry_time.time().strftime(\"%H:%M:%S\")\n",
    "\n",
    "# add the Core Data dictionary to the Core Data data set + a warning if the data exists to avoid duplicates\n",
    "if len(core_data)==0 or len(core_data[(core_data[\"Symbol\"]==symbol) & (core_data[\"Entry Time\"]==strftime_time)\n",
    "& (core_data[\"Date\"]==timestamp_date)])==0:    \n",
    "    core_dict = merge_two_dicts(core_key, core_dict)\n",
    "    core_data =  core_data.append(core_dict, ignore_index=True)\n",
    "    core_data.to_excel(\"Core Data.xlsx\",index = False) \n",
    "else:\n",
    "    print(\"******** WARNING: Given key already inserted   ********\")\n",
    "\n",
    "# download and add the Fundamentals dictionary to the Fundamentals data set \n",
    "if len(f_data)==0 or (len(f_data[(f_data[\"Symbol\"]==symbol) & (f_data[\"Date\"]==timestamp_date)])==0):\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    fundamentals= ticker.info\n",
    "    fundamentals= merge_two_dicts(core_key, fundamentals)\n",
    "    f_data =  f_data.append(fundamentals, ignore_index=True)\n",
    "    f_data.to_excel(\"Fundamentals.xlsx\",index = False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Intra-day Data collection\n",
    "\n",
    "Different function for utilizing the data collection from the IB API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class TradeApp(EWrapper, EClient): \n",
    "    def __init__(self): \n",
    "        EClient.__init__(self, self) \n",
    "        self.data = {}\n",
    "        \n",
    "    def historicalData(self, reqId, bar):\n",
    "        if reqId not in self.data:\n",
    "            self.data[reqId] = [{\"Datetime\":bar.date,\"Open\":bar.open,\"High\":bar.high,\"Low\":bar.low,\"Close\":bar.close,\"Volume\":bar.volume}]\n",
    "        else:\n",
    "            self.data[reqId].append({\"Datetime\":bar.date,\"Open\":bar.open,\"High\":bar.high,\"Low\":bar.low,\"Close\":bar.close,\"Volume\":bar.volume})\n",
    "        #print(\"reqID:{}, date:{}, open:{}, high:{}, low:{}, close:{}, volume:{}\".format(reqId,bar.date,bar.open,bar.high,bar.low,bar.close,bar.volume))\n",
    "\n",
    "def usTechStk(symbol,sec_type=\"STK\",currency=\"USD\",exchange=\"ISLAND\"):\n",
    "    contract = Contract()\n",
    "    contract.symbol = symbol\n",
    "    contract.secType = sec_type\n",
    "    contract.currency = currency\n",
    "    contract.exchange = exchange\n",
    "    return contract \n",
    "\n",
    "def histData(req_num,contract,endDate,duration,candle_size):\n",
    "    \"\"\"extracts historical data\"\"\"\n",
    "    app.reqHistoricalData(reqId=req_num, \n",
    "                          contract=contract,\n",
    "                          endDateTime=endDate,\n",
    "                          durationStr=duration,\n",
    "                          barSizeSetting=candle_size,\n",
    "                          whatToShow='TRADES',\n",
    "                          useRTH=1,\n",
    "                          formatDate=1,\n",
    "                          keepUpToDate=0,\n",
    "                          chartOptions=[])\t # EClient function to request contract details    \n",
    "\n",
    "# storing trade app object data (the downloaded data) in a dataframe \n",
    "def dataDataframe(symbols,TradeApp_obj):\n",
    "    \"returns extracted historical data in dataframe format\"\n",
    "    df_data = {}\n",
    "    i=0\n",
    "    for symbol in symbols:\n",
    "        df_data[symbol] = pd.DataFrame(TradeApp_obj.data[i])\n",
    "        df_data[symbol].set_index(\"Datetime\",inplace=True)\n",
    "        i+=1\n",
    "    return df_data\n",
    "\n",
    "# convert string to datetime and validate the time\n",
    "def datetimeCon(x):\n",
    "    date_time_obj = datetime.datetime.strptime(x, '%Y%m%d %H:%M:%S')\n",
    "    if date_time_obj.time()< datetime.time(9,30) or date_time_obj.time()>datetime.time(16,0):\n",
    "        print(\"******** WARNING: Unsual time, change IB time-zone ********\")\n",
    "        print(date_time_obj.time())\n",
    "        sys.exit()\n",
    "    return date_time_obj\n",
    "\n",
    "# connect to web socket with multi threading\n",
    "def websocket_con():\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Raw Data\n",
    "\n",
    "In this cell we will download the bar data from the soreces as mentioned abov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR -1 2104 Market data farm connection is OK:usfarm.nj\n",
      "ERROR -1 2104 Market data farm connection is OK:usfarm\n",
      "ERROR -1 2106 HMDS data farm connection is OK:euhmds\n",
      "ERROR -1 2106 HMDS data farm connection is OK:ushmds.nj\n",
      "ERROR -1 2106 HMDS data farm connection is OK:fundfarm\n",
      "ERROR -1 2106 HMDS data farm connection is OK:ushmds\n",
      "ERROR -1 2158 Sec-def data farm connection is OK:secdefil\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index Symbol       Date\n",
      "0     59   FCEL 2021-04-22\n",
      "1     61   FWAA 2021-04-22\n",
      "2     62   OCGN 2021-04-22\n",
      "FCEL 20210422 23:59:00\n",
      "FWAA 20210422 23:59:00\n",
      "OCGN 20210422 23:59:00\n",
      "FCEL\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "FWAA\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "OCGN\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "#import the Core Data\n",
    "core_data =  pd.read_excel('Core Data.xlsx') \n",
    "\n",
    "# Filter the data to get only the rows where data has not yet been downloaded (where the column Download is 0)\n",
    "download_data = core_data[core_data[\"Download\"]==0][[\"Symbol\",\"Date\"]].drop_duplicates().reset_index()\n",
    "print(download_data)\n",
    "\n",
    "\n",
    "# connect to IB server\n",
    "app = TradeApp()\n",
    "app.connect(host='127.0.0.1', port=7497, clientId=23) #port 4002 for ib gateway paper trading/7497 for TWS paper trading\n",
    "con_thread = threading.Thread(target=websocket_con, daemon=True)\n",
    "con_thread.start()\n",
    "time.sleep(1) # some latency added to ensure that the connection is established\n",
    "\n",
    "\n",
    "# make an API call to download the 1 minute data from IB\n",
    "for index,row in download_data.iterrows():    \n",
    "    date = datetime.datetime.combine(row[\"Date\"].date(),datetime.time(23,59)).strftime(\"%Y%m%d %H:%M:%S\")\n",
    "    \n",
    "    \n",
    "    symbol = row[\"Symbol\"] \n",
    "    dict_download = {\"Symbol\": symbol,\"Date\":date}\n",
    "    \n",
    "    print(str(symbol)+ \" \" + date)\n",
    "    histData(index,usTechStk(symbol),date,'1 D', '1 min')\n",
    "    time.sleep(5)\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "#extract and store IB 1 minute data in dataframes\n",
    "historicalData = dataDataframe(download_data[\"Symbol\"].values,app)\n",
    "\n",
    "# store the data localy\n",
    "# store intraday IB data from the broker\n",
    "\n",
    "    \n",
    "# store intraday and D1 data from Yahoo finance, IB and merge the Yahoo volume only with the IB data \n",
    "\n",
    "#the local directories for the bar data\n",
    "directory1 = 'Yahoo Intraday Data'\n",
    "directory2 = 'Yahoo D1 Data'\n",
    "directory3 = 'Yahoo H1 Data'\n",
    "directory4 = 'IB Intraday Data'\n",
    "directory5 = 'Merged Intraday Data'\n",
    "directory6 = 'SPY Intraday Data'\n",
    "\n",
    "time_period1 = 365 # 1 year\n",
    "time_period2 = 30 #1 month\n",
    "\n",
    "# for every symbol download the intrady,1h and 1d bar data\n",
    "for key in historicalData:\n",
    "    print(key)\n",
    "    \n",
    "    \n",
    "    date_timestamp = historicalData[key].index[0].split()[0]\n",
    "    date = datetime.datetime.strptime(date_timestamp, '%Y%m%d').date()\n",
    "    \n",
    "    # download the 1 minute data from Yahoo Finance\n",
    "    minute_data_yahoo =  yf.download(key, start = date, end =  (date + datetime.timedelta(days=1)), interval = \"1m\" )  \n",
    "    \n",
    "    # Remove time zone from date-time index value\n",
    "    minute_data_yahoo.index = minute_data_yahoo.index.map(lambda x: datetime.datetime.combine(x.date(),x.time()).strftime(\"%Y%m%d  %H:%M:%S\"))\n",
    "    \n",
    "    # download the d1 and 1h bar data from Yahoo Finance\n",
    "    d1_data=  yf.download(key, start = (date - datetime.timedelta(days=time_period1)), end =  (date + datetime.timedelta(days=1)), interval = \"1d\" )\n",
    "    h1_data=  yf.download(key, start = (date - datetime.timedelta(days=time_period2)), end =  (date + datetime.timedelta(days=1)), interval = \"1h\" )\n",
    "\n",
    "    #create strings for file names\n",
    "    file_name = key + ' ' + date_timestamp + '.xlsx'\n",
    "    spy_data_file_name = \"SPY \"+date_timestamp + \".xlsx\"\n",
    "    \n",
    "    spy_files =os.listdir(directory6)\n",
    "    \n",
    "    if spy_data_file_name not in spy_files:\n",
    "            spy_minute_data_yahoo =  yf.download(\"SPY\", start = date, end =  (date + datetime.timedelta(days=1)), interval = \"1m\" )\n",
    "            spy_minute_data_yahoo.index = spy_minute_data_yahoo.index.map(lambda x: datetime.datetime.combine(x.date(),x.time()).strftime(\"%Y%m%d  %H:%M:%S\"))\n",
    "            directory_destination = \"SPY Intraday Data\"\n",
    "    \n",
    "\n",
    "            path6 = os.path.join(directory6, spy_data_file_name)\n",
    "            spy_minute_data_yahoo.to_excel(path6)\n",
    "        \n",
    "\n",
    "    \n",
    "    # merge the data so that high,low, open, close are taken from IB and Volume is taken from Yahoo\n",
    "    merged_data = pd.merge(historicalData[key].drop(columns = [\"Volume\"]),minute_data_yahoo[[\"Volume\"]],on='Datetime',how='left')\n",
    "    merged_data[\"Volume\"] =merged_data[\"Volume\"].fillna(0) \n",
    "    \n",
    "    # every session is 390 minutes starting at 9:30 and ending at the end of 15:59\n",
    "    # leave a warning if some minutes are missing\n",
    "    minutes_per_session = 390\n",
    "    if len(merged_data)!=minutes_per_session:\n",
    "        print(\"******** WARNING: The length is not 390, please fix the lenth of symbol\" + key +\" ********\")\n",
    "        \n",
    "    \n",
    "    \n",
    "    #local paths to the directories\n",
    "    path1 = os.path.join(directory1, file_name)\n",
    "    path2 = os.path.join(directory2, file_name)\n",
    "    path3 = os.path.join(directory3, file_name)\n",
    "    path4 = os.path.join(directory4, file_name)\n",
    "    path5 = os.path.join(directory5, file_name)\n",
    "    \n",
    "    \n",
    "    # save the datasets in excel files in the paths\n",
    "    minute_data_yahoo.to_excel(path1)\n",
    "    d1_data.to_excel(path2)\n",
    "    h1_data.to_excel(path3)\n",
    "    historicalData[key].to_excel(path4)\n",
    "    merged_data.to_excel(path5)\n",
    "\n",
    "# update the core_data table, change download to 1 from 0 to signal that the data has been downloaded\n",
    "core_data[\"Download\"] =  core_data[\"Download\"].replace({0:1})\n",
    "core_data.to_excel('Core Data.xlsx',index = False) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
